{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e4375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (4.0.0)\n",
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/pytorch/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.22.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00af57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model:int, vocab_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea380862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[18,  4,  0, 12, 13],\n",
      "        [ 6, 19,  1, 13, 18]])\n",
      "\n",
      "Embeddings (with scaling):\n",
      " tensor([[[ 3.4491,  0.2286, -1.9196, -1.1250, -1.5951, -4.0762, -2.5758,\n",
      "           0.2742],\n",
      "         [ 0.8067,  0.1462, -1.9222,  0.1486,  8.9591,  1.0481, -0.0172,\n",
      "          -2.9542],\n",
      "         [ 2.2098,  0.8158,  1.7288,  6.6945, -2.6517, -0.2257, -0.3454,\n",
      "          -1.1235],\n",
      "         [ 2.5378,  1.3919,  0.8215,  0.9555, -5.4037, -0.9901,  4.1008,\n",
      "          -2.1832],\n",
      "         [-4.5013, -1.0218, -4.2245, -1.9338, -3.1929,  1.2192,  5.0253,\n",
      "          -2.1403]],\n",
      "\n",
      "        [[ 4.1163, -2.1206,  1.5288,  1.4586, -4.3398, -2.7935,  2.9121,\n",
      "           0.4308],\n",
      "         [ 2.5680, -0.1862, -3.9832, -3.2019,  1.8529,  3.7834,  2.4422,\n",
      "           3.2996],\n",
      "         [ 2.1117,  2.2335,  2.9434, -1.8628,  0.5726, -0.6750,  0.8177,\n",
      "          -1.1282],\n",
      "         [-4.5013, -1.0218, -4.2245, -1.9338, -3.1929,  1.2192,  5.0253,\n",
      "          -2.1403],\n",
      "         [ 3.4491,  0.2286, -1.9196, -1.1250, -1.5951, -4.0762, -2.5758,\n",
      "           0.2742]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "Norm of each embedding vector (after scaling):\n",
      " tensor([[6.5398, 9.7201, 7.8624, 7.8568, 9.1873],\n",
      "        [7.8236, 8.2065, 4.9301, 9.1873, 6.5398]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d_model = 8\n",
    "vocab_size = 20\n",
    "batch_size, seq_len = 2, 5\n",
    "\n",
    "layer = InputEmbeddings(d_model, vocab_size)\n",
    "\n",
    "# Some random token IDs\n",
    "tokens = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "print(\"Token IDs:\\n\", tokens)\n",
    "\n",
    "# Raw embeddings (with scaling)\n",
    "out = layer(tokens)\n",
    "print(\"\\nEmbeddings (with scaling):\\n\", out)\n",
    "\n",
    "# To see their size, print the L2 norm of each token vector\n",
    "norms = out.norm(dim=-1)\n",
    "print(\"\\nNorm of each embedding vector (after scaling):\\n\", norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f36b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodings(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) \n",
    "        pe[:, 1::2] = torch.cos(position * div_term) \n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe',pe)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9028681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (before PE): torch.Size([2, 5, 8])\n",
      "out shape (after PE): torch.Size([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "pos_enc = PositionalEncodings(d_model=8, seq_len=10, dropout=0.1)\n",
    "\n",
    "# 2. Example: a batch of 2 sentences, each with 5 tokens, already embedded\n",
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "x = torch.randn(batch_size, sentence_len, 8)   # random \"word embeddings\"\n",
    "\n",
    "print(\"x shape (before PE):\", x.shape)\n",
    "\n",
    "# 3. Pass through positional encoding\n",
    "out = pos_enc(x)\n",
    "print(\"out shape (after PE):\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, eps:float=10**-6) ->None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(-1,keepdim=True)\n",
    "        std = x.std(-1,keepdim=True)\n",
    "        return self.alpha * (x- mean)/(std+ self.eps) +self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21cd4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [10., 20., 30., 40.]])\n",
      "\n",
      "Output after LayerNorm:\n",
      " tensor([[-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "        [-1.1619, -0.3873,  0.3873,  1.1619]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Means per token after LN: tensor([2.9802e-08, 0.0000e+00], grad_fn=<MeanBackward1>)\n",
      "Stds per token after LN : tensor([1.0000, 1.0000], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1.0, 2.0, 3.0, 4.0],   # token 1\n",
    "    [10.0, 20.0, 30.0, 40.0] # token 2\n",
    "])  # shape (2, 4)  → 2 tokens, each with 4 features\n",
    "\n",
    "ln = LayerNormalization()\n",
    "y = ln(x)\n",
    "\n",
    "print(\"Input:\\n\", x)\n",
    "print(\"\\nOutput after LayerNorm:\\n\", y)\n",
    "\n",
    "print(\"\\nMeans per token after LN:\", y.mean(-1))\n",
    "print(\"Stds per token after LN :\", y.std(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b49a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model:int, d_ff:int, dropout:float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model,d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff,d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ec4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model:int, d_ff:int,dropout:float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model,d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff,d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear_2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28844b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = FeedForwardBlock(d_model,4,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d111d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1269,  0.3162,  0.1710, -0.1655,  0.1602,  0.3027,  0.3432,  0.1178],\n",
      "        [-0.3214,  0.2370,  0.0436, -0.1921, -0.1559, -0.1383,  0.1379,  0.3234],\n",
      "        [-0.3188, -0.0098, -0.1927,  0.2922, -0.3168,  0.0318, -0.0399, -0.1380],\n",
      "        [ 0.2942,  0.1490,  0.1625,  0.1909,  0.0427, -0.3282, -0.3020, -0.3361]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0643,  0.2582,  0.1838, -0.0065], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2226,  0.0374,  0.3586, -0.4606],\n",
      "        [ 0.2924, -0.0257, -0.4766, -0.2877],\n",
      "        [-0.4734, -0.4928,  0.2585, -0.0011],\n",
      "        [-0.1279, -0.0049,  0.4666,  0.3178],\n",
      "        [ 0.4280,  0.3211,  0.4056, -0.3529],\n",
      "        [-0.0875, -0.1814, -0.0928, -0.2676],\n",
      "        [-0.0136, -0.0587, -0.1025,  0.3429],\n",
      "        [-0.0009,  0.3429, -0.0039,  0.3891]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4030,  0.0007,  0.1408,  0.0383, -0.3972, -0.2768, -0.4139, -0.4143],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in ff.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ccb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "torch.Size([4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(ff.linear_1.weight.shape)\n",
    "print(ff.linear_1.bias.shape)\n",
    "print(ff.linear_2.weight.shape)\n",
    "print(ff.linear_2.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcce9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1269,  0.3162,  0.1710, -0.1655,  0.1602,  0.3027,  0.3432,  0.1178],\n",
      "        [-0.3214,  0.2370,  0.0436, -0.1921, -0.1559, -0.1383,  0.1379,  0.3234],\n",
      "        [-0.3188, -0.0098, -0.1927,  0.2922, -0.3168,  0.0318, -0.0399, -0.1380],\n",
      "        [ 0.2942,  0.1490,  0.1625,  0.1909,  0.0427, -0.3282, -0.3020, -0.3361]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0643,  0.2582,  0.1838, -0.0065], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2226,  0.0374,  0.3586, -0.4606],\n",
      "        [ 0.2924, -0.0257, -0.4766, -0.2877],\n",
      "        [-0.4734, -0.4928,  0.2585, -0.0011],\n",
      "        [-0.1279, -0.0049,  0.4666,  0.3178],\n",
      "        [ 0.4280,  0.3211,  0.4056, -0.3529],\n",
      "        [-0.0875, -0.1814, -0.0928, -0.2676],\n",
      "        [-0.0136, -0.0587, -0.1025,  0.3429],\n",
      "        [-0.0009,  0.3429, -0.0039,  0.3891]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4030,  0.0007,  0.1408,  0.0383, -0.3972, -0.2768, -0.4139, -0.4143],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(ff.linear_1.weight)\n",
    "print(ff.linear_1.bias)\n",
    "print(ff.linear_2.weight)\n",
    "print(ff.linear_2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fbe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model:int, h:int , dropout:float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "\n",
    "        assert d_model // h == 0, 'd_model is not divisible by h'\n",
    "\n",
    "        self.d_k = self.d_model // h\n",
    "        self.w_q = nn.Linear(d_model,d_model)\n",
    "        self.w_v = nn.Linear(d_model,d_model)\n",
    "        self.w_k = nn.Linear(d_model,d_model)\n",
    "\n",
    "        self.w_o = nn.Linear(d_model,d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k=query.shape[-1]\n",
    "\n",
    "        attention_score = (query @ key.transpose(-1,-2))/math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_score.masked_fill(mask == 0 , -1e9)\n",
    "        attention_score = attention_score.softmax(dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            attention_score = dropout(attention_score)\n",
    "        \n",
    "        return (attention_score @value) , attention_score\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, q,k,v, mask):\n",
    "        query = self.w_q(q)\n",
    "        key = self.w_k(k)\n",
    "        value = self.w_v(v)\n",
    "\n",
    "        query = query.vew(query.shape[0], query.hsape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        key = key.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1 ,2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1 ,2)\n",
    "\n",
    "        x, self.attention_score = self.attention(query, key, value, mask, self.dropout)\n",
    "\n",
    "        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "        return self.w_o(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98daa442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout:float):\n",
    "        self.dropout = dropout\n",
    "        self.norm = LayerNormalization()\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf6fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout:float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_forward_block)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layers: nn.modul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3175460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : torch.Size([2, 4, 8])\n",
      "Input sample:\n",
      " tensor([[ 0.8573, -0.0609,  1.1974,  0.1148,  0.6154, -1.0930,  1.9597, -1.2311],\n",
      "        [ 1.3614,  1.9327,  0.6628,  0.3425, -0.1720,  0.0820,  0.4570, -0.5169],\n",
      "        [-0.6505,  1.4195,  0.9332,  1.0570,  0.4678,  0.7032, -1.0348, -0.5908],\n",
      "        [ 1.6712, -0.5148,  1.1786,  1.0540, -1.8952, -1.2580, -0.1011,  0.3994]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example input (batch=2, seq_len=4, d_model=8)\n",
    "x = torch.randn(2, 4, 8)   # fake embeddings\n",
    "\n",
    "# Example mask (no masking here, just pass None if you want)\n",
    "mask = None\n",
    "\n",
    "print(\"Input shape :\", x.shape)\n",
    "print(\"Input sample:\\n\", x[0])  # first sentence in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8945565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layers: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,mask)\n",
    "\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0d5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
