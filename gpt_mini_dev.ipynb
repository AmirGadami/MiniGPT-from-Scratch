{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5e4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00af57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model:int, vocab_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea380862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[14,  1, 18, 14,  3],\n",
      "        [ 6, 17, 18,  9, 12]])\n",
      "\n",
      "Embeddings (with scaling):\n",
      " tensor([[[ 3.1498, -5.8949,  2.5421, -0.7695,  2.0498,  0.0136, -3.4912,\n",
      "          -0.5024],\n",
      "         [ 1.4175,  8.3697,  3.1052,  6.5225, -3.0622,  0.9387,  2.8692,\n",
      "           4.7533],\n",
      "         [ 1.8225,  1.1268, -2.9127,  1.5103,  1.2764,  2.2662, -1.6036,\n",
      "          -2.1378],\n",
      "         [ 3.1498, -5.8949,  2.5421, -0.7695,  2.0498,  0.0136, -3.4912,\n",
      "          -0.5024],\n",
      "         [-0.4442, -1.1071, -6.5675,  0.5003,  0.5041, -0.6278, -3.3942,\n",
      "          -2.6709]],\n",
      "\n",
      "        [[ 0.3182,  0.8019, -2.9850, -1.4625,  0.5113,  5.4729, -0.9389,\n",
      "          -1.2096],\n",
      "         [-6.7336, -0.8448,  2.8472, -3.8637,  2.2501,  1.1553,  3.4675,\n",
      "           3.0849],\n",
      "         [ 1.8225,  1.1268, -2.9127,  1.5103,  1.2764,  2.2662, -1.6036,\n",
      "          -2.1378],\n",
      "         [-1.8019,  1.9768,  2.5436, -1.2389,  2.1357,  0.1672,  1.7539,\n",
      "          -3.1171],\n",
      "         [-4.7433,  0.8906, -0.9285, -2.9469, -5.2080,  1.4571, -1.1343,\n",
      "          -1.9419]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "Norm of each embedding vector (after scaling):\n",
      " tensor([[ 8.2685, 12.8581,  5.4095,  8.2685,  8.0067],\n",
      "        [ 6.6598,  9.8502,  5.4095,  5.7045,  8.1941]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d_model = 8\n",
    "vocab_size = 20\n",
    "batch_size, seq_len = 2, 5\n",
    "\n",
    "layer = InputEmbeddings(d_model, vocab_size)\n",
    "\n",
    "# Some random token IDs\n",
    "tokens = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "print(\"Token IDs:\\n\", tokens)\n",
    "\n",
    "# Raw embeddings (with scaling)\n",
    "out = layer(tokens)\n",
    "print(\"\\nEmbeddings (with scaling):\\n\", out)\n",
    "\n",
    "# To see their size, print the L2 norm of each token vector\n",
    "norms = out.norm(dim=-1)\n",
    "print(\"\\nNorm of each embedding vector (after scaling):\\n\", norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22f36b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodings(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) \n",
    "        pe[:, 1::2] = torch.cos(position * div_term) \n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe',pe)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9028681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (before PE): torch.Size([2, 5, 8])\n",
      "out shape (after PE): torch.Size([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "pos_enc = PositionalEncodings(d_model=8, seq_len=10, dropout=0.1)\n",
    "\n",
    "# 2. Example: a batch of 2 sentences, each with 5 tokens, already embedded\n",
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "x = torch.randn(batch_size, sentence_len, 8)   # random \"word embeddings\"\n",
    "\n",
    "print(\"x shape (before PE):\", x.shape)\n",
    "\n",
    "# 3. Pass through positional encoding\n",
    "out = pos_enc(x)\n",
    "print(\"out shape (after PE):\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "237484a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence A shapes -> tokens: torch.Size([1, 4]) emb: torch.Size([1, 4, 8]) with PE: torch.Size([1, 4, 8])\n",
      "Sentence B shapes -> tokens: torch.Size([1, 7]) emb: torch.Size([1, 7, 8]) with PE: torch.Size([1, 7, 8])\n",
      "\n",
      "Sentence A, token at pos 1:\n",
      "  embedding only:       tensor([-1.2621,  2.1044,  4.3020,  9.6464, -4.3308, -3.4907,  5.1470, -1.5600],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "  + positional encoding: tensor([-0.4206,  2.6447,  4.4018, 10.6414, -4.3208, -2.4907,  5.1480, -0.5600],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "As expected: seq_len > max_len causes an error:\n",
      "  The size of tensor a (12) must match the size of tensor b (10) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# ---- Your classes (unchanged) ----\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model:int, vocab_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncodings(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)                             # (max_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)                   # even dims\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)                   # odd dims\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))                    # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "# ---- Demo: different-length sentences with the same modules ----\n",
    "torch.manual_seed(0)\n",
    "\n",
    "d_model = 8\n",
    "vocab_size = 50\n",
    "max_len_for_pe = 10     # this is the maximum length we precomputed PE for\n",
    "dropout = 0.0           # set to 0.1 if you want to see dropout in action\n",
    "\n",
    "embed = InputEmbeddings(d_model, vocab_size)\n",
    "posenc = PositionalEncodings(d_model, seq_len=max_len_for_pe, dropout=dropout)\n",
    "\n",
    "# Sentence A: length 4 tokens\n",
    "tokens_A = torch.tensor([[4, 7, 13, 2]])               # shape (batch=1, seq_len=4)\n",
    "x_A = embed(tokens_A)                                  # (1, 4, d_model)\n",
    "y_A = posenc(x_A)                                      # (1, 4, d_model)\n",
    "\n",
    "# Sentence B: length 7 tokens\n",
    "tokens_B = torch.tensor([[1, 12, 15, 6, 19, 3, 9]])    # shape (1, 7)\n",
    "x_B = embed(tokens_B)                                  # (1, 7, d_model)\n",
    "y_B = posenc(x_B)                                      # (1, 7, d_model)\n",
    "\n",
    "print(\"Sentence A shapes -> tokens:\", tokens_A.shape, \"emb:\", x_A.shape, \"with PE:\", y_A.shape)\n",
    "print(\"Sentence B shapes -> tokens:\", tokens_B.shape, \"emb:\", x_B.shape, \"with PE:\", y_B.shape)\n",
    "\n",
    "# Peek at one token to see the effect of adding position\n",
    "i = 0   # batch index\n",
    "t = 1   # position index inside the sentence\n",
    "print(\"\\nSentence A, token at pos 1:\")\n",
    "print(\"  embedding only:      \", x_A[i, t])\n",
    "print(\"  + positional encoding:\", y_A[i, t])\n",
    "\n",
    "# Safety: what happens if a sentence is LONGER than max_len_for_pe?\n",
    "try:\n",
    "    tokens_long = torch.randint(0, vocab_size, (1, 12))   # seq_len=12 > max_len_for_pe=10\n",
    "    x_long = embed(tokens_long)\n",
    "    y_long = posenc(x_long)                                # expected to fail\n",
    "except Exception as e:\n",
    "    print(\"\\nAs expected: seq_len > max_len causes an error:\")\n",
    "    print(\" \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6858ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
